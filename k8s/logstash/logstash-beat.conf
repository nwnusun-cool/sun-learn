# Sample Logstash configuration for creating a simple
# Beats -> Logstash -> Elasticsearch pipeline.

input {
  beats {
    port => 5044
  }
  #stdin{}
}
filter {
   if [fields][type] == "DSTORE" {
	  grok {
		match => { "message" => "\[%{TIMESTAMP_ISO8601:logTime}\]\s+\[%{DATA:traceId}\]\s+\[%{DATA:thread}\]\s+\[%{LOGLEVEL:loglevel}\]\s+\[%{DATA:className}\]\s+\[*%{DATA:method}\]\s+\[%{INT:line}\]\s+%{GREEDYDATA:logContent}" }
	  }
	  date {
		match => [ "logTime", "yyyy-MM-dd HH:mm:ss.SSS","ISO8601" ]
		#match => [ "unixLogTime", "UNIX" ]
		locale => "en"
		timezone => "+08:00"
		#remove_field => "logTime"
	  }
	  ruby{
        code => "event.set('unixLogTime',(event.get('@timestamp').to_f.round(3)*1000).to_i)"
      }
      ruby {
        code => "
             event.set('logSuffix', event.get('logTime')[0..9])
        "
      }
	  mutate {
		remove_field => "agent"
		remove_field => "ecs"
		remove_field => "@version"
		#remove_field => "host"
		#remove_field => "path"
		#remove_field => "log"
		remove_field => "message"
		remove_field => "tags"
		remove_field => "input"
	  }
	  mutate {
        add_field => { "hostName" => "%{[host][hostname]}" }
      }
	  mutate {
		add_field => { "logPath" => "%{[log][file][path]}.%{logSuffix}" }
		add_field => { "path" => "%{[log][file][path]}.%{logSuffix}" }
		add_field => { "serviceName" => "DSTORE" }
		add_field => { "componentName" => "DStore" }
	  }
	  mutate {
		split => ["path", "/"]
		add_field => { "logFileName" => "%{[path][-1]}" }
	  }
	  mutate {
		remove_field => "tags"
		remove_field => "path"
		remove_field => "host"
		remove_field => "log"
	  }
	  mutate {
        gsub => [ "logPath", "/", " " ]
      }
	  mutate {
		strip => ["logPath"]
      }
   }
   if [fields][type] == "ALERTMANAGER" {
	  grok {
		match => { "message" => "%{DATA:logHead}:\s+%{DATA:loglevel_}\s+%{DATA:logTime_}\s+%{DATA:method}\s+%{GREEDYDATA:logContent}" }
	  }
	  mutate {
		split => ["loglevel_", "="]
		add_field => { "loglevel" => "%{[loglevel_][1]}" }
		remove_field => "loglevel_"
	  }
	  ruby {
		code => 'event.set("loglevel", event.get("loglevel").upcase)'
	  }
      if [loglevel] !~ "(ERROR|WARN|INFO|DEBUG)" {
      # 删除日志
        drop {}
      }
	  mutate {
		split => ["logTime_", "="]
		add_field => { "logTime" => "%{[logTime_][1]}" }
		remove_field => "logTime_"
	  }
	  date {
		match => [ "logTime", "yyyy-MM-dd HH:mm:ss,SSS","ISO8601" ]
		#match => [ "unixLogTime", "UNIX" ]
		#locale => "en"
		#timezone => "+00:00"
		#remove_field => "logTime"
	  }
	  ruby{
        code => "event.set('unixLogTime',(event.get('@timestamp').to_f.round(3)*1000).to_i)"
      }
      ruby {
        code => "
             event.set('logSuffix', event.get('logTime')[0..9])
        "
      }
	  mutate {
		remove_field => "agent"
		remove_field => "ecs"
		remove_field => "@version"
		#remove_field => "host"
		#remove_field => "path"
		#remove_field => "log"
		#remove_field => "message"
		remove_field => "tags"
		remove_field => "input"
	  }
	  mutate {
        add_field => { "hostName" => "%{[host][hostname]}" }
      }
	  mutate {
		add_field => { "logPath" => "%{[log][file][path]}" }
		add_field => { "path" => "%{[log][file][path]}" }
		add_field => { "serviceName" => "ALERTMANAGER" }
		add_field => { "componentName" => "Alertmanager" }
	  }
	  mutate {
		split => ["path", "/"]
		add_field => { "logFileName" => "%{[path][-1]}" }
	  }
	  mutate {
		remove_field => "tags"
		remove_field => "path"
		remove_field => "host"
		remove_field => "log"
	  }
	  mutate {
        gsub => [ "logPath", "/", " " ]
      }
	  mutate {
		strip => ["logPath"]
      }
   }
   if [fields][type] == "GRAFANA" {
	  grok {
		match => { "message" => "%{DATA:logHead}:\s+%{DATA:logAttr}\s+%{DATA:logTime_}\s+%{DATA:loglevel_}\s+%{GREEDYDATA:logContent}" }
	  }
	  mutate {
		split => ["loglevel_", "="]
		add_field => { "loglevel" => "%{[loglevel_][1]}" }
		remove_field => "loglevel_"
	  }
	  ruby {
		code => 'event.set("loglevel", event.get("loglevel").upcase)'
	  }
      if [loglevel] !~ "(ERROR|WARN|INFO|DEBUG)" {
      # 删除日志
        drop {}
      }
	  mutate {
		split => ["logTime_", "="]
		add_field => { "logTime" => "%{[logTime_][1]}" }
		remove_field => "logTime_"
	  }
	  date {
		match => [ "logTime", "yyyy-MM-dd HH:mm:ss.SSS","ISO8601" ]
		#match => [ "unixLogTime", "UNIX" ]
		#locale => "en"
		#timezone => "+00:00"
		#remove_field => "logTime"
	  }
	  ruby{
        code => "event.set('unixLogTime',(event.get('@timestamp').to_f.round(3)*1000).to_i)"
      }
      ruby {
        code => "
             event.set('logSuffix', event.get('logTime')[0..9])
        "
      }
	  mutate {
		remove_field => "agent"
		remove_field => "ecs"
		remove_field => "@version"
		#remove_field => "host"
		#remove_field => "path"
		#remove_field => "log"
		remove_field => "message"
		remove_field => "tags"
		remove_field => "input"
	  }
	  mutate {
        add_field => { "hostName" => "%{[host][hostname]}" }
      }
	  mutate {
		add_field => { "logPath" => "%{[log][file][path]}" }
		add_field => { "path" => "%{[log][file][path]}" }
		add_field => { "serviceName" => "GRAFANA" }
		add_field => { "componentName" => "Grafana" }
	  }
	  mutate {
		split => ["path", "/"]
		add_field => { "logFileName" => "%{[path][-1]}" }
	  }
	  mutate {
		remove_field => "tags"
		remove_field => "path"
		remove_field => "host"
		remove_field => "log"
	  }
	  mutate {
        gsub => [ "logPath", "/", " " ]
      }
	  mutate {
		strip => ["logPath"]
      }
   }
   if [fields][type] == "LOGSTASH" {
	  grok {
		match => { "message" => "\[%{TIMESTAMP_ISO8601:logTime}\]\[%{DATA:loglevel}\s+\]\[%{DATA:className}\s+\]%{GREEDYDATA:logContent}" }
	  }
	  date {
		match => [ "logTime", "yyyy-MM-dd HH:mm:ss,SSS","ISO8601" ]
		#match => [ "unixLogTime", "UNIX" ]
		#locale => "en"
		#timezone => "+00:00"
		#remove_field => "logTime"
	  }
	  ruby{
        code => "event.set('unixLogTime',(event.get('@timestamp').to_f.round(3)*1000).to_i)"
      }
      ruby {
        code => "
             event.set('logSuffix', event.get('logTime')[0..9])
        "
      }

	  mutate {
		remove_field => "agent"
		remove_field => "ecs"
		remove_field => "@version"
		#remove_field => "host"
		#remove_field => "path"
		#remove_field => "log"
		remove_field => "message"
		remove_field => "tags"
		remove_field => "input"
	  }
	  mutate {
        add_field => { "hostName" => "%{[host][hostname]}" }
      }
	  mutate {
		add_field => { "logPath" => "%{[log][file][path]}.%{logSuffix}" }
		add_field => { "path" => "%{[log][file][path]}.%{logSuffix}" }
		add_field => { "serviceName" => "LOGSTASH" }
		add_field => { "componentName" => "Logstash" }
	  }
	  mutate {
		split => ["path", "/"]
		add_field => { "logFileName" => "%{[path][-1]}" }
	  }
	  mutate {
		remove_field => "tags"
		remove_field => "path"
		remove_field => "host"
		remove_field => "log"
	  }
	  mutate {
        gsub => [ "logPath", "/", " " ]
      }
	  mutate {
		strip => ["logPath"]
      }
   }
   if [fields][type] == "MYSQL" {
	  grok {
		match => { "message" => "%{TIMESTAMP_ISO8601:logTime}\s+%{GREEDYDATA:logContent}" }
	  }
	  mutate {
		add_field => { "loglevel" => "INFO" }
	  }

	  date {
		match => [ "logTime", "yyyy-MM-dd HH:mm:ss,SSS","ISO8601" ]
		#match => [ "unixLogTime", "UNIX" ]
		#locale => "en"
		#timezone => "+00:00"
		#remove_field => "logTime"
	  }
	  ruby{
        code => "event.set('unixLogTime',(event.get('@timestamp').to_f.round(3)*1000).to_i)"
      }
      ruby {
        code => "
             event.set('logSuffix', event.get('logTime')[0..9])
        "
      }

	  mutate {
		remove_field => "agent"
		remove_field => "ecs"
		remove_field => "@version"
		#remove_field => "host"
		#remove_field => "path"
		#remove_field => "log"
		remove_field => "message"
		remove_field => "tags"
		remove_field => "input"
	  }
	  mutate {
        add_field => { "hostName" => "%{[host][hostname]}" }
      }
	  mutate {
		add_field => { "logPath" => "%{[log][file][path]}" }
		add_field => { "path" => "%{[log][file][path]}" }
		add_field => { "serviceName" => "MYSQL" }
		add_field => { "componentName" => "MySQL" }
	  }
	  mutate {
		split => ["path", "/"]
		add_field => { "logFileName" => "%{[path][-1]}" }
	  }
	  mutate {
		remove_field => "tags"
		remove_field => "path"
		remove_field => "host"
		remove_field => "log"
	  }
	  mutate {
        gsub => [ "logPath", "/", " " ]
      }
	  mutate {
		strip => ["logPath"]
      }
   }
   if [fields][type] == "PROMETHEUS" {
	  grok {
		match => { "message" => "%{DATA:logHead}:\s+%{DATA:logTime_}\s+%{DATA:method_}\s+%{DATA:loglevel_}\s+%{GREEDYDATA:logContent}" }
	  }
	  mutate {
		split => ["loglevel_", "="]
		add_field => { "loglevel" => "%{[loglevel_][1]}" }
		remove_field => "loglevel_"
	  }
	  ruby {
		code => 'event.set("loglevel", event.get("loglevel").upcase)'
	  }
      if [loglevel] !~ "(ERROR|WARN|INFO|DEBUG)" {
      # 删除日志
        drop {}
      }
	  mutate {
		split => ["logTime_", "="]
		add_field => { "logTime" => "%{[logTime_][1]}" }
		remove_field => "logTime_"
	  }
	  date {
		match => [ "logTime", "yyyy-MM-dd HH:mm:ss.SSS","ISO8601" ]
		#match => [ "unixLogTime", "UNIX" ]
		#locale => "en"
		#timezone => "+00:00"
		#remove_field => "logTime"
	  }
	  ruby{
        code => "event.set('unixLogTime',(event.get('@timestamp').to_f.round(3)*1000).to_i)"
      }
      ruby {
        code => "
             event.set('logSuffix', event.get('logTime')[0..9])
        "
      }
	  mutate {
		remove_field => "agent"
		remove_field => "ecs"
		remove_field => "@version"
		#remove_field => "host"
		#remove_field => "path"
		#remove_field => "log"
		remove_field => "message"
		remove_field => "tags"
		remove_field => "input"
	  }
	  mutate {
        add_field => { "hostName" => "%{[host][hostname]}" }
      }
	  mutate {
		add_field => { "logPath" => "%{[log][file][path]}" }
		add_field => { "path" => "%{[log][file][path]}" }
		add_field => { "serviceName" => "PROMETHEUS" }
		add_field => { "componentName" => "Prometheus" }
	  }
	  mutate {
		split => ["path", "/"]
		add_field => { "logFileName" => "%{[path][-1]}" }
	  }
	  mutate {
		remove_field => "tags"
		remove_field => "path"
		remove_field => "host"
		remove_field => "log"
	  }
	  mutate {
        gsub => [ "logPath", "/", " " ]
      }
	  mutate {
		strip => ["logPath"]
      }
   }
   if [fields][type] == "ROCKETMQ" {
	  grok {
		match => { "message" => "%{TIMESTAMP_ISO8601:logTime}\s+%{DATA:loglevel}\s+%{DATA:thread}\s+-\s+%{GREEDYDATA:logContent}" }
	  }
	  date {
		match => [ "logTime", "yyyy-MM-dd HH:mm:ss","ISO8601" ]
		#match => [ "unixLogTime", "UNIX" ]
		locale => "en"
		timezone => "+08:00"
		#remove_field => "logTime"
	  }
	  ruby{
        code => "event.set('unixLogTime',(event.get('@timestamp').to_f.round(3)*1000).to_i)"
      }
      ruby {
        code => "
             event.set('logSuffix', event.get('logTime')[0..9])
        "
      }

	  mutate {
		remove_field => "agent"
		remove_field => "ecs"
		remove_field => "@version"
		#remove_field => "host"
		#remove_field => "path"
		#remove_field => "log"
		remove_field => "message"
		remove_field => "tags"
		remove_field => "input"
	  }
	  mutate {
        add_field => { "hostName" => "%{[host][hostname]}" }
      }
	  mutate {
		add_field => { "logPath" => "%{[log][file][path]}.%{logSuffix}" }
		add_field => { "path" => "%{[log][file][path]}.%{logSuffix}" }
		add_field => { "serviceName" => "ROCKETMQ" }
		add_field => { "componentName" => "RocketMQ" }
	  }
	  mutate {
		split => ["path", "/"]
		add_field => { "logFileName" => "%{[path][-1]}" }
	  }
	  mutate {
		remove_field => "tags"
		remove_field => "path"
		remove_field => "host"
		remove_field => "log"
	  }
	  mutate {
        gsub => [ "logPath", "/", " " ]
      }
	  mutate {
		strip => ["logPath"]
      }
   }
   if [fields][type] == "AGENT" {
	  grok {
		match => { "message" => "\[%{TIMESTAMP_ISO8601:logTime}\]\s+\[%{DATA:thread}\]\s+\[%{DATA:loglevel}\]\s+\[%{DATA:className}\]\s+\[%{DATA:module}\]\s+\[%{DATA:line}\]\s+%{GREEDYDATA:logContent}" }
	  }
	  date {
		match => [ "logTime", "yyyy-MM-dd HH:mm:ss,SSS","ISO8601" ]
		#match => [ "unixLogTime", "UNIX" ]
		locale => "en"
		timezone => "+08:00"
		#remove_field => "logTime"
	  }
	  ruby{
        code => "event.set('unixLogTime',(event.get('@timestamp').to_f.round(3)*1000).to_i)"
      }
      ruby {
        code => "
             event.set('logSuffix', event.get('logTime')[0..9])
        "
      }

	  mutate {
		remove_field => "agent"
		remove_field => "ecs"
		remove_field => "@version"
		#remove_field => "host"
		#remove_field => "path"
		#remove_field => "log"
		remove_field => "message"
		remove_field => "tags"
		remove_field => "input"
	  }
	  mutate {
		add_field => { "logPath" => "%{[log][file][path]}.%{logSuffix}" }
		add_field => { "path" => "%{[log][file][path]}.%{logSuffix}" }
		add_field => { "serviceName" => "AGENT" }
		add_field => { "componentName" => "Agent" }
	  }
	  mutate {
		split => ["path", "/"]
		add_field => { "logFileName" => "%{[path][-1]}" }
		add_field => { "cluster" => "%{[path][5]}" }
	  }
	  mutate {
		remove_field => "tags"
		remove_field => "path"
		remove_field => "host"
		remove_field => "log"
	  }
	  mutate {
		add_field => { "logFileName_" => "%{logFileName}" }
	  }
	  mutate {
		split => ["logFileName_", "-"]
		add_field => { "hostName_" => "%{[logFileName_][1]}" }
	  }
	  mutate {
		split => ["hostName_", "."]
		add_field => { "hostName" => "%{[hostName_][0]}" }
	  }
	  mutate {
		remove_field => "logFileName_"
		remove_field => "hostName_"
	  }
	  mutate {
        gsub => [ "logPath", "/", " " ]
      }
	  mutate {
		strip => ["logPath"]
      }
   }
   if [fields][type] == "ES" {
	  grok {
		match => { "message" => "\[%{TIMESTAMP_ISO8601:logTime}\]\[%{DATA:loglevel}\s+\]\[%{DATA:className}\]\s+\[%{DATA:node}\]\s+%{GREEDYDATA:logContent}" }
	  }
	  date {
		match => [ "logTime", "yyyy-MM-dd HH:mm:ss,SSS","ISO8601" ]
		#match => [ "unixLogTime", "UNIX" ]
		#locale => "en"
		timezone => "+08:00"
		#remove_field => "logTime"
	  }
	  ruby{
        code => "event.set('unixLogTime',(event.get('@timestamp').to_f.round(3)*1000).to_i)"
      }
      ruby {
        code => "
             event.set('logSuffix', event.get('logTime')[0..9])
        "
      }
      ruby {
          code => "
            value = event.get('message')
            require 'digest/md5'
            md5 = Digest::MD5::hexdigest(value)
            event.set('uniqueKey', md5)
          "
      }
	  mutate {
		remove_field => "agent"
		remove_field => "ecs"
		remove_field => "@version"
		#remove_field => "host"
		#remove_field => "path"
		#remove_field => "log"
		remove_field => "message"
		remove_field => "tags"
		remove_field => "input"
	  }
	  mutate {
		add_field => { "logPath" => "%{[log][file][path]}.%{logSuffix}" }
		add_field => { "path" => "%{[log][file][path]}.%{logSuffix}" }
		add_field => { "serviceName" => "ELASTICSEARCH" }
		add_field => { "componentName" => "ES_Server" }
	  }
	  mutate {
		split => ["path", "/"]
		add_field => { "logFileName" => "%{[path][-1]}" }
		add_field => { "cluster" => "%{[path][5]}" }
		add_field => { "hostName" => "%{[path][6]}" }
	  }
	  mutate {
		remove_field => "tags"
		remove_field => "path"
		remove_field => "host"
		remove_field => "log"
	  }
	  mutate {
        gsub => [ "logPath", "/", " " ]
      }
	  mutate {
		strip => ["logPath"]
      }
   }
   if [fields][type] == "FLINK" {
	  grok {
		match => { "message" => "\[%{TIMESTAMP_ISO8601:logTime}\]\s+%{DATA:loglevel}\s+%{DATA:className}\s+\[%{DATA:thread}\]\s+-\s+%{GREEDYDATA:logContent}" }
	  }
	  date {
		match => [ "logTime", "yyyy-MM-dd HH:mm:ss,SSS","ISO8601" ]
		#match => [ "unixLogTime", "UNIX" ]
		locale => "en"
		timezone => "+08:00"
		#remove_field => "logTime"
	  }
	  ruby{
        code => "event.set('unixLogTime',(event.get('@timestamp').to_f.round(3)*1000).to_i)"
      }
      ruby {
        code => "
             event.set('logSuffix', event.get('logTime')[0..9])
        "
      }
      ruby {
          code => "
            value = event.get('message')
            require 'digest/md5'
            md5 = Digest::MD5::hexdigest(value)
            event.set('uniqueKey', md5)
          "
      }
	  mutate {
		remove_field => "agent"
		remove_field => "ecs"
		remove_field => "@version"
		#remove_field => "host"
		#remove_field => "path"
		#remove_field => "log"
		remove_field => "message"
		remove_field => "tags"
		remove_field => "input"
	  }
	  mutate {
		add_field => { "logPath" => "%{[log][file][path]}.%{logSuffix}" }
		add_field => { "path" => "%{[log][file][path]}.%{logSuffix}" }
		add_field => { "serviceName" => "FLINK" }
		add_field => { "componentName" => "FlinkServer" }
	  }
	  mutate {
		split => ["path", "/"]
		add_field => { "logFileName" => "%{[path][-1]}" }
		add_field => { "cluster" => "%{[path][5]}" }
		add_field => { "hostName" => "%{[path][6]}" }
	  }
	  mutate {
		remove_field => "tags"
		remove_field => "path"
		remove_field => "host"
		remove_field => "log"
	  }
	  mutate {
        gsub => [ "logPath", "/", " " ]
      }
	  mutate {
		strip => ["logPath"]
      }
   }
   if [fields][type] == "HDFS_DN" {
	  grok {
		match => { "message" => "\[%{TIMESTAMP_ISO8601:logTime}\]\s+%{DATA:loglevel}\s+%{DATA:className}\s+%{GREEDYDATA:logContent}" }
	  }
	  date {
		match => [ "logTime", "yyyy-MM-dd HH:mm:ss,SSS","ISO8601" ]
		#match => [ "unixLogTime", "UNIX" ]
		locale => "en"
		timezone => "+08:00"
		#remove_field => "logTime"
	  }
	  ruby{
        code => "event.set('unixLogTime',(event.get('@timestamp').to_f.round(3)*1000).to_i)"
      }
      ruby {
        code => "
             event.set('logSuffix', event.get('logTime')[0..9])
        "
      }

	  mutate {
		remove_field => "agent"
		remove_field => "ecs"
		remove_field => "@version"
		#remove_field => "host"
		#remove_field => "path"
		#remove_field => "log"
		remove_field => "message"
		remove_field => "tags"
		remove_field => "input"
	  }
	  mutate {
		add_field => { "logPath" => "%{[log][file][path]}.%{logSuffix}" }
		add_field => { "path" => "%{[log][file][path]}.%{logSuffix}" }
		add_field => { "serviceName" => "HDFS" }
		add_field => { "componentName" => "DataNode" }
	  }
	  mutate {
		split => ["path", "/"]
		add_field => { "logFileName" => "%{[path][-1]}" }
		add_field => { "cluster" => "%{[path][5]}" }
		add_field => { "hostName" => "%{[path][6]}" }
	  }
	  mutate {
		remove_field => "tags"
		remove_field => "path"
		remove_field => "host"
		remove_field => "log"
	  }
	  mutate {
        gsub => [ "logPath", "/", " " ]
      }
	  mutate {
		strip => ["logPath"]
      }
   }
   if [fields][type] == "HDFS_JN" {
	  grok {
		match => { "message" => "\[%{TIMESTAMP_ISO8601:logTime}\]\s+%{DATA:loglevel}\s+%{DATA:className}\s+%{GREEDYDATA:logContent}" }
	  }
	  date {
		match => [ "logTime", "yyyy-MM-dd HH:mm:ss,SSS","ISO8601" ]
		#match => [ "unixLogTime", "UNIX" ]
		locale => "en"
		timezone => "+08:00"
		#remove_field => "logTime"
	  }
	  ruby{
        code => "event.set('unixLogTime',(event.get('@timestamp').to_f.round(3)*1000).to_i)"
      }
      ruby {
        code => "
             event.set('logSuffix', event.get('logTime')[0..9])
        "
      }

	  mutate {
		remove_field => "agent"
		remove_field => "ecs"
		remove_field => "@version"
		#remove_field => "host"
		#remove_field => "path"
		#remove_field => "log"
		remove_field => "message"
		remove_field => "tags"
		remove_field => "input"
	  }
	  mutate {
		add_field => { "logPath" => "%{[log][file][path]}.%{logSuffix}" }
		add_field => { "path" => "%{[log][file][path]}.%{logSuffix}" }
		add_field => { "serviceName" => "HDFS" }
		add_field => { "componentName" => "JournalNode" }
	  }
	  mutate {
		split => ["path", "/"]
		add_field => { "logFileName" => "%{[path][-1]}" }
		add_field => { "cluster" => "%{[path][5]}" }
		add_field => { "hostName" => "%{[path][6]}" }
	  }
	  mutate {
		remove_field => "tags"
		remove_field => "path"
		remove_field => "host"
		remove_field => "log"
	  }
	  mutate {
        gsub => [ "logPath", "/", " " ]
      }
	  mutate {
		strip => ["logPath"]
      }
   }
   if [fields][type] == "HDFS_NN" {
	  grok {
		match => { "message" => "\[%{TIMESTAMP_ISO8601:logTime}\]\s+%{DATA:loglevel}\s+%{DATA:className}\s+%{GREEDYDATA:logContent}" }
	  }
	  date {
		match => [ "logTime", "yyyy-MM-dd HH:mm:ss,SSS","ISO8601" ]
		#match => [ "unixLogTime", "UNIX" ]
		locale => "en"
		timezone => "+08:00"
		#remove_field => "logTime"
	  }
	  ruby{
        code => "event.set('unixLogTime',(event.get('@timestamp').to_f.round(3)*1000).to_i)"
      }
      ruby {
        code => "
             event.set('logSuffix', event.get('logTime')[0..9])
        "
      }

	  mutate {
		remove_field => "agent"
		remove_field => "ecs"
		remove_field => "@version"
		#remove_field => "host"
		#remove_field => "path"
		#remove_field => "log"
		remove_field => "message"
		remove_field => "tags"
		remove_field => "input"
	  }
	  mutate {
		add_field => { "logPath" => "%{[log][file][path]}.%{logSuffix}" }
		add_field => { "path" => "%{[log][file][path]}.%{logSuffix}" }
		add_field => { "serviceName" => "HDFS" }
		add_field => { "componentName" => "NameNode" }
	  }
	  mutate {
		split => ["path", "/"]
		add_field => { "logFileName" => "%{[path][-1]}" }
		add_field => { "cluster" => "%{[path][5]}" }
		add_field => { "hostName" => "%{[path][6]}" }
	  }
	  mutate {
		remove_field => "tags"
		remove_field => "path"
		remove_field => "host"
		remove_field => "log"
	  }
	  mutate {
        gsub => [ "logPath", "/", " " ]
      }
	  mutate {
		strip => ["logPath"]
      }
   }
   if [fields][type] == "HDFS_ZKFC" {
	  grok {
		match => { "message" => "\[%{TIMESTAMP_ISO8601:logTime}\]\s+%{DATA:loglevel}\s+%{DATA:className}\s+%{GREEDYDATA:logContent}" }
	  }
	  date {
		match => [ "logTime", "yyyy-MM-dd HH:mm:ss,SSS","ISO8601" ]
		#match => [ "unixLogTime", "UNIX" ]
		locale => "en"
		timezone => "+08:00"
		#remove_field => "logTime"
	  }
	  ruby{
        code => "event.set('unixLogTime',(event.get('@timestamp').to_f.round(3)*1000).to_i)"
      }
      ruby {
        code => "
             event.set('logSuffix', event.get('logTime')[0..9])
        "
      }

	  mutate {
		remove_field => "agent"
		remove_field => "ecs"
		remove_field => "@version"
		#remove_field => "host"
		#remove_field => "path"
		#remove_field => "log"
		remove_field => "message"
		remove_field => "tags"
		remove_field => "input"
	  }
	  mutate {
		add_field => { "logPath" => "%{[log][file][path]}.%{logSuffix}" }
		add_field => { "path" => "%{[log][file][path]}.%{logSuffix}" }
		add_field => { "serviceName" => "HDFS" }
		add_field => { "componentName" => "ZKFailoverController" }
	  }
	  mutate {
		split => ["path", "/"]
		add_field => { "logFileName" => "%{[path][-1]}" }
		add_field => { "cluster" => "%{[path][5]}" }
		add_field => { "hostName" => "%{[path][6]}" }
	  }
	  mutate {
		remove_field => "tags"
		remove_field => "path"
		remove_field => "host"
		remove_field => "log"
	  }
	  mutate {
        gsub => [ "logPath", "/", " " ]
      }
	  mutate {
		strip => ["logPath"]
      }
   }
   if [fields][type] == "HIVE" {
	  grok {
		match => { "message" => "\[%{TIMESTAMP_ISO8601:logTime}\]\s+%{DATA:loglevel}\s+\[%{DATA:thread}\]\s+%{DATA:className}\s+%{GREEDYDATA:logContent}" }
	  }
	  date {
		match => [ "logTime", "yyyy-MM-dd HH:mm:ss,SSS","ISO8601" ]
		#match => [ "unixLogTime", "UNIX" ]
		locale => "en"
		timezone => "+08:00"
		#remove_field => "logTime"
	  }
	  ruby{
        code => "event.set('unixLogTime',(event.get('@timestamp').to_f.round(3)*1000).to_i)"
      }
      ruby {
        code => "
             event.set('logSuffix', event.get('logTime')[0..9])
        "
      }
      ruby {
          code => "
            value = event.get('message')
            require 'digest/md5'
            md5 = Digest::MD5::hexdigest(value)
            event.set('uniqueKey', md5)
          "
      }
	  mutate {
		remove_field => "agent"
		remove_field => "ecs"
		remove_field => "@version"
		#remove_field => "host"
		#remove_field => "path"
		#remove_field => "log"
		remove_field => "message"
		remove_field => "tags"
		remove_field => "input"
	  }
	  mutate {
		add_field => { "logPath" => "%{[log][file][path]}.%{logSuffix}" }
		add_field => { "path" => "%{[log][file][path]}.%{logSuffix}" }
		add_field => { "serviceName" => "HIVE" }
		add_field => { "componentName" => "HiveMetastore" }
	  }
	  mutate {
		split => ["path", "/"]
		add_field => { "logFileName" => "%{[path][-1]}" }
		add_field => { "cluster" => "%{[path][5]}" }
		add_field => { "hostName" => "%{[path][6]}" }
	  }
	  mutate {
		remove_field => "tags"
		remove_field => "path"
		remove_field => "host"
		remove_field => "log"
	  }
	  mutate {
        gsub => [ "logPath", "/", " " ]
      }
	  mutate {
		strip => ["logPath"]
      }
   }
   if [fields][type] == "KAFKA" {
	  grok {
		match => { "message" => "\[%{TIMESTAMP_ISO8601:logTime}\]\s+%{DATA:loglevel}\s+%{GREEDYDATA:logContent}\s+\(%{DATA:class}\)" }
	  }
	  date {
		match => [ "logTime", "yyyy-MM-dd HH:mm:ss,SSS","ISO8601" ]
		#match => [ "unixLogTime", "UNIX" ]
		locale => "en"
		timezone => "+08:00"
		#remove_field => "logTime"
	  }
	  ruby{
        code => "event.set('unixLogTime',(event.get('@timestamp').to_f.round(3)*1000).to_i)"
      }
      ruby {
        code => "
             event.set('logSuffix', event.get('logTime')[0..9])
        "
      }

	  mutate {
		remove_field => "agent"
		remove_field => "ecs"
		remove_field => "@version"
		#remove_field => "host"
		#remove_field => "path"
		#remove_field => "log"
		remove_field => "message"
		remove_field => "tags"
		remove_field => "input"
	  }
	  mutate {
		add_field => { "logPath" => "%{[log][file][path]}.%{logSuffix}" }
		add_field => { "path" => "%{[log][file][path]}.%{logSuffix}" }
		add_field => { "serviceName" => "KAFKA" }
		add_field => { "componentName" => "Broker" }
	  }
	  mutate {
		split => ["path", "/"]
		add_field => { "logFileName" => "%{[path][-1]}" }
		add_field => { "cluster" => "%{[path][5]}" }
		add_field => { "hostName" => "%{[path][6]}" }
	  }
	  mutate {
		remove_field => "tags"
		remove_field => "path"
		remove_field => "host"
		remove_field => "log"
	  }
	  mutate {
        gsub => [ "logPath", "/", " " ]
      }
	  mutate {
		strip => ["logPath"]
      }
   }
   if [fields][type] == "RANGER_ADMIN" {
	  grok {
		match => { "message" => "\[%{TIMESTAMP_ISO8601:logTime}\]\s+\[%{DATA:thread}\]\s+%{DATA:loglevel}\s+\[%{DATA:logAttr}\]\s+%{GREEDYDATA:logContent}" }
	  }
	  date {
		match => [ "logTime", "yyyy-MM-dd HH:mm:ss,SSS","ISO8601" ]
		#match => [ "unixLogTime", "UNIX" ]
		locale => "en"
		timezone => "+08:00"
		#remove_field => "logTime"
	  }
	  ruby{
        code => "event.set('unixLogTime',(event.get('@timestamp').to_f.round(3)*1000).to_i)"
      }
      ruby {
        code => "
             event.set('logSuffix', event.get('logTime')[0..9])
        "
      }

	  mutate {
		remove_field => "agent"
		remove_field => "ecs"
		remove_field => "@version"
		#remove_field => "host"
		#remove_field => "path"
		#remove_field => "log"
		remove_field => "message"
		remove_field => "tags"
		remove_field => "input"
	  }
	  mutate {
		add_field => { "logPath" => "%{[log][file][path]}.%{logSuffix}" }
		add_field => { "path" => "%{[log][file][path]}.%{logSuffix}" }
		add_field => { "serviceName" => "RANGER" }
		add_field => { "componentName" => "RangerAdmin" }
	  }
	  mutate {
		split => ["path", "/"]
		add_field => { "logFileName" => "%{[path][-1]}" }
		add_field => { "cluster" => "%{[path][5]}" }
		add_field => { "hostName" => "%{[path][6]}" }
	  }
	  mutate {
		split => ["logAttr", ":"]
		add_field => { "className" => "%{[logAttr][0]}" }
		add_field => { "line" => "%{[logAttr][1]}" }
	  }
	  mutate {
		remove_field => "tags"
		remove_field => "path"
		remove_field => "host"
		remove_field => "log"
		remove_field => "logAttr"
	  }
	  mutate {
        gsub => [ "logPath", "/", " " ]
      }
	  mutate {
		strip => ["logPath"]
      }
   }
   if [fields][type] == "RANGER_USERSYNC" {
	  grok {
		match => { "message" => "\[%{TIMESTAMP_ISO8601:logTime}\]\s+%{DATA:loglevel}\s+%{DATA:className}\s+\[%{DATA:thread}\]\s+-\s+%{GREEDYDATA:logContent}" }
	  }
	  date {
		match => [ "logTime", "yyyy-MM-dd HH:mm:ss,SSS","ISO8601" ]
		#match => [ "unixLogTime", "UNIX" ]
		#locale => "en"
		timezone => "+08:00"
		#remove_field => "logTime"
	  }
	  ruby{
        code => "event.set('unixLogTime',(event.get('@timestamp').to_f.round(3)*1000).to_i)"
      }
      ruby {
        code => "
             event.set('logSuffix', event.get('logTime')[0..9])
        "
      }

	  mutate {
		remove_field => "agent"
		remove_field => "ecs"
		remove_field => "@version"
		#remove_field => "host"
		#remove_field => "path"
		#remove_field => "log"
		remove_field => "message"
		remove_field => "tags"
		remove_field => "input"
	  }
	  mutate {
		add_field => { "logPath" => "%{[log][file][path]}.%{logSuffix}" }
		add_field => { "path" => "%{[log][file][path]}.%{logSuffix}" }
		add_field => { "serviceName" => "RANGER" }
		add_field => { "componentName" => "RangerUsersync" }
	  }
	  mutate {
		split => ["path", "/"]
		add_field => { "logFileName" => "%{[path][-1]}" }
		add_field => { "cluster" => "%{[path][5]}" }
		add_field => { "hostName" => "%{[path][6]}" }
	  }
	  mutate {
		remove_field => "tags"
		remove_field => "path"
		remove_field => "host"
		remove_field => "log"
	  }
	  mutate {
        gsub => [ "logPath", "/", " " ]
      }
	  mutate {
		strip => ["logPath"]
      }
   }
   if [fields][type] == "SPARK" {
	  grok {
		match => { "message" => "\[%{TIMESTAMP_ISO8601:logTime}\]\s+-\s+%{DATA:loglevel}\s+\[%{DATA:logAttr}\]\s+-\s+%{GREEDYDATA:logContent}" }
	  }
	  date {
		match => [ "logTime", "yy/MM/dd HH:mm:ss","ISO8601" ]
		#match => [ "unixLogTime", "UNIX" ]
		locale => "en"
		timezone => "+08:00"
		#remove_field => "logTime"
	  }
	  ruby{
        code => "event.set('unixLogTime',(event.get('@timestamp').to_f.round(3)*1000).to_i)"
      }
      ruby {
        code => "
             event.set('logSuffix', event.get('logTime')[0..9])
        "
      }

	  mutate {
		remove_field => "agent"
		remove_field => "ecs"
		remove_field => "@version"
		#remove_field => "host"
		#remove_field => "path"
		#remove_field => "log"
		remove_field => "message"
		remove_field => "tags"
		remove_field => "input"
	  }
	  mutate {
		add_field => { "logPath" => "%{[log][file][path]}.%{logSuffix}" }
		add_field => { "path" => "%{[log][file][path]}.%{logSuffix}" }
		add_field => { "serviceName" => "SPARK" }
		add_field => { "componentName" => "HistoryServer" }
	  }

	  mutate {
		split => ["path", "/"]
		add_field => { "logFileName" => "%{[path][-1]}" }
		add_field => { "cluster" => "%{[path][5]}" }
		add_field => { "hostName" => "%{[path][6]}" }
	  }
	  mutate {
		remove_field => "tags"
		remove_field => "path"
		remove_field => "host"
		remove_field => "log"
	  }
	  mutate {
		split => ["logAttr", ":"]
		add_field => { "thread" => "%{[logAttr][0]}" }
		add_field => { "logAttr_" => "%{[logAttr][1]}" }
	  }
	  mutate {
		split => ["logAttr_", "@"]
		add_field => { "className" => "%{[logAttr_][0]}" }
		add_field => { "line" => "%{[logAttr_][1]}" }
	  }
	  mutate {
		remove_field => "logAttr"
		remove_field => "logAttr_"
	  }

	  mutate {
        gsub => [ "logPath", "/", " " ]
      }
	  mutate {
		strip => ["logPath"]
      }
   }
   if [fields][type] == "YARN_HS" {
	  grok {
		match => { "message" => "\[%{TIMESTAMP_ISO8601:logTime}\]\s+%{DATA:loglevel}\s+%{DATA:className}\s+%{GREEDYDATA:logContent}" }
	  }
	  date {
		match => [ "logTime", "yyyy-MM-dd HH:mm:ss,SSS","ISO8601" ]
		#match => [ "unixLogTime", "UNIX" ]
		locale => "en"
		timezone => "+08:00"
		#remove_field => "logTime"
	  }
	  ruby{
        code => "event.set('unixLogTime',(event.get('@timestamp').to_f.round(3)*1000).to_i)"
      }
      ruby {
        code => "
             event.set('logSuffix', event.get('logTime')[0..9])
        "
      }

	  mutate {
		remove_field => "agent"
		remove_field => "ecs"
		remove_field => "@version"
		#remove_field => "host"
		#remove_field => "path"
		#remove_field => "log"
		remove_field => "message"
		remove_field => "tags"
		remove_field => "input"
	  }
	  mutate {
		add_field => { "logPath" => "%{[log][file][path]}.%{logSuffix}" }
		add_field => { "path" => "%{[log][file][path]}.%{logSuffix}" }
		add_field => { "serviceName" => "YARN" }
		add_field => { "componentName" => "JobHistoryServer" }
	  }
	  mutate {
		split => ["path", "/"]
		add_field => { "logFileName" => "%{[path][-1]}" }
		add_field => { "cluster" => "%{[path][5]}" }
		add_field => { "hostName" => "%{[path][6]}" }
	  }
	  mutate {
		remove_field => "tags"
		remove_field => "path"
		remove_field => "host"
		remove_field => "log"
	  }
	  mutate {
        gsub => [ "logPath", "/", " " ]
      }
	  mutate {
		strip => ["logPath"]
      }
   }
   if [fields][type] == "YARN_NM" {
	  grok {
		match => { "message" => "\[%{TIMESTAMP_ISO8601:logTime}\]\s+%{DATA:loglevel}\s+%{DATA:className}\s+%{GREEDYDATA:logContent}" }
	  }
	  date {
		match => [ "logTime", "yyyy-MM-dd HH:mm:ss,SSS","ISO8601" ]
		#match => [ "unixLogTime", "UNIX" ]
		locale => "en"
		timezone => "+08:00"
		#remove_field => "logTime"
	  }
	  ruby{
        code => "event.set('unixLogTime',(event.get('@timestamp').to_f.round(3)*1000).to_i)"
      }
      ruby {
        code => "
             event.set('logSuffix', event.get('logTime')[0..9])
        "
      }

	  mutate {
		remove_field => "agent"
		remove_field => "ecs"
		remove_field => "@version"
		#remove_field => "host"
		#remove_field => "path"
		#remove_field => "log"
		remove_field => "message"
		remove_field => "tags"
		remove_field => "input"
	  }
	  mutate {
		add_field => { "logPath" => "%{[log][file][path]}.%{logSuffix}" }
		add_field => { "path" => "%{[log][file][path]}.%{logSuffix}" }
		add_field => { "serviceName" => "YARN" }
		add_field => { "componentName" => "NodeManager" }
	  }
	  mutate {
		split => ["path", "/"]
		add_field => { "logFileName" => "%{[path][-1]}" }
		add_field => { "cluster" => "%{[path][5]}" }
		add_field => { "hostName" => "%{[path][6]}" }
	  }
	  mutate {
		remove_field => "tags"
		remove_field => "path"
		remove_field => "host"
		remove_field => "log"
	  }
	  mutate {
        gsub => [ "logPath", "/", " " ]
      }
	  mutate {
		strip => ["logPath"]
      }
   }
   if [fields][type] == "YARN_RM" {
	  grok {
		match => { "message" => "\[%{TIMESTAMP_ISO8601:logTime}\]\s+%{DATA:loglevel}\s+%{DATA:className}\s+%{GREEDYDATA:logContent}" }
	  }
	  date {
		match => [ "logTime", "yyyy-MM-dd HH:mm:ss,SSS","ISO8601" ]
		#match => [ "unixLogTime", "UNIX" ]
		locale => "en"
		timezone => "+08:00"
		#remove_field => "logTime"
	  }
	  ruby{
        code => "event.set('unixLogTime',(event.get('@timestamp').to_f.round(3)*1000).to_i)"
      }
      ruby {
        code => "
             event.set('logSuffix', event.get('logTime')[0..9])
        "
      }

	  mutate {
		remove_field => "agent"
		remove_field => "ecs"
		remove_field => "@version"
		#remove_field => "host"
		#remove_field => "path"
		#remove_field => "log"
		remove_field => "message"
		remove_field => "tags"
		remove_field => "input"
	  }
	  mutate {
		add_field => { "logPath" => "%{[log][file][path]}.%{logSuffix}" }
		add_field => { "path" => "%{[log][file][path]}.%{logSuffix}" }
		add_field => { "serviceName" => "YARN" }
		add_field => { "componentName" => "ResourceManager" }
	  }
	  mutate {
		split => ["path", "/"]
		add_field => { "logFileName" => "%{[path][-1]}" }
		add_field => { "cluster" => "%{[path][5]}" }
		add_field => { "hostName" => "%{[path][6]}" }
	  }
	  mutate {
		remove_field => "tags"
		remove_field => "path"
		remove_field => "host"
		remove_field => "log"
	  }
	  mutate {
        gsub => [ "logPath", "/", " " ]
      }
	  mutate {
		strip => ["logPath"]
      }
   }
   if [fields][type] == "ZOOKEEPER" {
	  grok {
		match => { "message" => "\[%{TIMESTAMP_ISO8601:logTime}\]\s+\[%{DATA:myid}\]\s+-\s+%{DATA:loglevel}\s+%{GREEDYDATA:logContent}" }
	  }
	  date {
		match => [ "logTime", "yyyy-MM-dd HH:mm:ss,SSS","ISO8601" ]
		#match => [ "unixLogTime", "UNIX" ]
		locale => "en"
		timezone => "+08:00"
		#remove_field => "logTime"
	  }
	  ruby{
        code => "event.set('unixLogTime',(event.get('@timestamp').to_f.round(3)*1000).to_i)"
      }
      ruby {
        code => "
             event.set('logSuffix', event.get('logTime')[0..9])
        "
      }

	  mutate {
		remove_field => "agent"
		remove_field => "ecs"
		remove_field => "@version"
		#remove_field => "host"
		#remove_field => "path"
		#remove_field => "log"
		remove_field => "message"
		remove_field => "tags"
		remove_field => "input"
	  }
	  mutate {
		add_field => { "logPath" => "%{[log][file][path]}.%{logSuffix}" }
		add_field => { "path" => "%{[log][file][path]}.%{logSuffix}" }
		add_field => { "serviceName" => "ZOOKEEPER" }
		add_field => { "componentName" => "Server" }
	  }
	  mutate {
		split => ["path", "/"]
		add_field => { "logFileName" => "%{[path][-1]}" }
		add_field => { "cluster" => "%{[path][5]}" }
		add_field => { "hostName" => "%{[path][6]}" }
	  }
	  mutate {
		remove_field => "tags"
		remove_field => "path"
		remove_field => "host"
		remove_field => "log"
	  }
	  mutate {
        gsub => [ "logPath", "/", " " ]
      }
	  mutate {
		strip => ["logPath"]
      }
   }
}
output {
  if [fields][type] == "DSTORE" {
	  http {
		url => "http://${DSTORE_HTTP}/api/v5/resourceLog/createLuceneIndexDSTORE"
		http_method => "post"
		socket_timeout => 30
		format => "json_batch"
		headers => {
		  "Content-Type" => "application/json"
		}
	  }
  } else if [fields][type] == "ALERTMANAGER" {
	  http {
		url => "http://${DSTORE_HTTP}/api/v5/resourceLog/createLuceneIndexALERTHANAGER"
		http_method => "post"
		socket_timeout => 30
		format => "json_batch"
		headers => {
		  "Content-Type" => "application/json"
		}
	  }
  } else if [fields][type] == "GRAFANA" {
	  http {
		url => "http://${DSTORE_HTTP}/api/v5/resourceLog/createLuceneIndexGRAFANA"
		http_method => "post"
		socket_timeout => 30
		format => "json_batch"
		headers => {
		  "Content-Type" => "application/json"
		}
	  }
  } else if[fields][type] == "PROMETHEUS" {
	  http {
		url => "http://${DSTORE_HTTP}/api/v5/resourceLog/createLuceneIndexPROMETHEUS"
		http_method => "post"
		socket_timeout => 30
		format => "json_batch"
		headers => {
		  "Content-Type" => "application/json"
		}
	  }
  } else if [fields][type] == "LOGSTASH" {
	  http {
		url => "http://${DSTORE_HTTP}/api/v5/resourceLog/createLuceneIndexLOGSTASH"
		http_method => "post"
		socket_timeout => 30
		format => "json_batch"
		headers => {
		  "Content-Type" => "application/json"
		}
	  }
  } else if [fields][type] == "MYSQL" {
	  http {
		url => "http://${DSTORE_HTTP}/api/v5/resourceLog/createLuceneIndexMYSQL"
		http_method => "post"
		socket_timeout => 30
		format => "json_batch"
		headers => {
		  "Content-Type" => "application/json"
		}
	  }
  } else if [fields][type] == "ROCKETMQ" {
	  http {
		url => "http://${DSTORE_HTTP}/api/v5/resourceLog/createLuceneIndexROCKETMQ"
		http_method => "post"
		socket_timeout => 30
		format => "json_batch"
		headers => {
		  "Content-Type" => "application/json"
		}
	  }
  } else if [fields][type] == "AGENT" {
	  http {
		url => "http://${DSTORE_HTTP}/api/v5/resourceLog/createLuceneIndexAGENT"
		http_method => "post"
		socket_timeout => 30
		format => "json_batch"
		headers => {
		  "Content-Type" => "application/json"
		}
	  }
  } else if [fields][type] == "ZOOKEEPER" {
	  http {
		url => "http://${DSTORE_HTTP}/api/v5/resourceLog/createLuceneIndexZOOKEEPER"
		http_method => "post"
		socket_timeout => 30
		format => "json_batch"
		headers => {
		  "Content-Type" => "application/json"
		}
	  }
  } else if [fields][type] in [ "HDFS_NN", "HDFS_DN", "HDFS_JN", "HDFS_ZKFC" ]{
	  http {
		url => "http://${DSTORE_HTTP}/api/v5/resourceLog/createLuceneIndexHDFS"
		http_method => "post"
		socket_timeout => 30
		format => "json_batch"
		headers => {
		  "Content-Type" => "application/json"
		}
	  }
  } else if [fields][type] in [ "YARN_RM", "YARN_NM", "YARN_HS" ]{
	  http {
		url => "http://${DSTORE_HTTP}/api/v5/resourceLog/createLuceneIndexYARN"
		http_method => "post"
		socket_timeout => 30
		format => "json_batch"
		headers => {
		  "Content-Type" => "application/json"
		}
	  }
  } else if [fields][type] == "HIVE" {
	  http {
		url => "http://${DSTORE_HTTP}/api/v5/resourceLog/createLuceneIndexHIVE"
		http_method => "post"
		socket_timeout => 30
		format => "json_batch"
		headers => {
		  "Content-Type" => "application/json"
		}
	  }
  } else if [fields][type] == "ES" {
	  http {
		url => "http://${DSTORE_HTTP}/api/v5/resourceLog/createLuceneIndexELASTICSEARCH"
		http_method => "post"
		socket_timeout => 30
		format => "json_batch"
		headers => {
		  "Content-Type" => "application/json"
		}
	  }
  } else if [fields][type] == "KAFKA" {
	  http {
		url => "http://${DSTORE_HTTP}/api/v5/resourceLog/createLuceneIndexKAFKA"
		http_method => "post"
		socket_timeout => 30
		format => "json_batch"
		headers => {
		  "Content-Type" => "application/json"
		}
	  }
  } else if [fields][type] == "SPARK" {
	  http {
		url => "http://${DSTORE_HTTP}/api/v5/resourceLog/createLuceneIndexSPARK"
		http_method => "post"
		socket_timeout => 30
		format => "json_batch"
		headers => {
		  "Content-Type" => "application/json"
		}
	  }
  } else if [fields][type] == "FLINK" {
	  http {
		url => "http://${DSTORE_HTTP}/api/v5/resourceLog/createLuceneIndexFLINK"
		http_method => "post"
		socket_timeout => 30
		format => "json_batch"
		headers => {
		  "Content-Type" => "application/json"
		}
	  }
  } else if [fields][type] in [ "RANGER_ADMIN", "RANGER_USERSYNC" ] {
	  http {
		url => "http://${DSTORE_HTTP}/api/v5/resourceLog/createLuceneIndexRANGER"
		http_method => "post"
		socket_timeout => 30
		format => "json_batch"
		headers => {
		  "Content-Type" => "application/json"
		}
	  }
  }
  #http {
  #  url => "http://192.168.2.16:8488/api/v5/resourceLog/createLuceneIndex"
  #  http_method => "post"
  #  format => "json"
  #  headers => {
  #    "Content-Type" => "application/json"
  #  }
  #}
  #stdout {
  #  codec => json
  #}
}
